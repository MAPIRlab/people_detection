#!/usr/bin/env python

import rospy
from cv_bridge import CvBridge, CvBridgeError
from sensor_msgs.msg import Image
from std_msgs.msg import Int16
from openpose_pkg.msg import *
from openpose_pkg.srv import *

#import os
import time
import numpy as np
import sys
import rospkg #for the ros pkg path
### Load model ###
from estimator2 import TfPoseEstimator
#opencv to copy the image
import cv2
import rosbag

#########################################################
##### OPENPOSE detects humans when an image arrived #####
#########################################################
## ToDo: improve detection
        
class OpenposeClass:

    def __init__(self):
        self._img_ready = False
        self._detect_humans = False
        self._tf_start = False
        self._low_frec = True
        self._off_frec = False
        self._compute_depth = False
        self._image_is_flip = False

        rospack = rospkg.RosPack()      
        self._models_path = rospack.get_path('openpose_pkg') + '/models/graph_opt.pb'       

        #node
        rospy.init_node('openpose_node')
        #for opencv
        self._bridge = CvBridge()

        ###############################
        ####    PARAMETERS         ####
        ###############################
        ## debug flag. show info
        self._debug = rospy.get_param('~DebugIngo/debug_info', False)

        # how many humans are we gonna detect ??
        self._single_human = rospy.get_param('~HumanDetected/single_human', False)

        ## threshold for the confidence of the detection
        self._threshold_human = rospy.get_param('~HumanDetected/threshold_human', 0.0)

        ## topics names
        self._topic_image_name =  rospy.get_param('~ROSTopics/image_topic', '/image_raw')
        self._topic_humans_name = rospy.get_param('~ROSTopics/humans_topic', '/humans')

        self._openpose = TfPoseEstimator(self._models_path)


        #####################
        ### DEBUG INFO    ###
        #####################
        if (self._debug):
            rospy.loginfo('Debug info activated')
            rospy.loginfo('Single detection: %d', self._single_human)
            rospy.loginfo('Threshold for the detection: %d', self._threshold_human)
            rospy.loginfo('Dimensions of the image: %d - %d', self._width_img, self._height_img)
            rospy.loginfo('Topic name for the image: %s', self._topic_image_name)
            rospy.loginfo('Topic name for the humans: %s', self._topic_humans_name)



    def humans_to_msg(self, humans, frame, cloud):
        humanArray_msg = HumanArray2() ## return array
        ## data about the image
        (rows, cols, chan) = frame.shape
        humanArray_msg.image_w = cols
        humanArray_msg.image_h = rows

        ##Image field
        ## header for the msg == header image
        humanArray_msg.header = self._header_ros
        new_image_msg = ImageDepthHuman()
        try:
            new_image_msg.image_2d = self._bridge.cv2_to_imgmsg(frame, "bgr8")
            new_image_msg.image_2d.header = self._header_ros
            new_image_msg.point_cloud_3d = cloud
            new_image_msg.valid_depth = self._compute_depth
            new_image_msg.detection_active = self._move_robot

            humanArray_msg.image_human = new_image_msg
        except CvBridgeError as e:
            pass

        ##humans
        ## how many humans depens on the self._single_human var
        n_humans = 0 ## intiial = 0

        if self._single_human:
            n_humans = 1 ## we just looked for one human
            ## JUST the first one
        else:
            n_humans = len(humans)
            ## we looked for all of them
        self._vel_window = [1.0, 0.0]

        
        if len(humans) >= n_humans:
            for k in range(n_humans):
                human_msg = self.single_human_msg(humans[k])
                if human_msg.certainty > self._threshold_human:
                    ## human is correct
                    humanArray_msg.humans.append(human_msg)
                
        return humanArray_msg

    def single_human_msg(self, human):
        human_msg = Human()
        part_scores = []
        ### x_values = []
        ### y_values = []
        for body_part in human.body_parts.values():
            bodyPart_msg = BodyPart()
            bodyPart_msg.idx = body_part.part_idx
            bodyPart_msg.x_percent = body_part.x
            bodyPart_msg.y_percent = body_part.y 
            if self._image_is_flip:
                bodyPart_msg.y_percent = 1.0 - body_part.y 
            bodyPart_msg.score = body_part.score
   
            part_scores.append(body_part.score)
            
            human_msg.parts.append(bodyPart_msg)
            ## if speech, here !!!!! do sth to change x,y to the whole
            ## image!!!
            
        human_msg.certainty = np.mean(part_scores)/10
      
        return human_msg

    def detect_humans(self):

        #publishers and subscribers

        ## cam topic
        self._sub_cam = rospy.Subscriber(self._topic_image_name, ImageDepthHuman, self.callback_image)
        ## humans parts and image where they were found topics
        self._pub_human = rospy.Publisher(self._topic_humans_name, HumanArray2, queue_size=1)


        ## this rate in unreal, we cannot achieve it!!
        r=rospy.Rate(500) #500 Hz

        while(not rospy.is_shutdown()):        
            r.sleep()

        ###self._bag.close()
        rospy.signal_shutdown("Exiting openpose node.\n")
        sys.exit(1)

    def callback_image(self, frame_ros):
    	
        try:
            self._header_ros = frame_ros.image_2d.header
            self._frame_cv = self._bridge.imgmsg_to_cv2(frame_ros.image_2d, "bgr8")
            self._cloud = frame_ros.point_cloud_3d
            self._compute_depth = frame_ros.valid_depth
            self._image_is_flip = frame_ros.image_flip

            self._move_robot = frame_ros.detection_active
            self._img_ready = True
            self.publish_human_pose()
            self._img_ready = False
        except CvBridgeError as e:
            pass
        
        
        
    def publish_human_pose(self):
        ## copy the image into another var
        self._frame_humans = cv2.copyMakeBorder(self._frame_cv, 0, 0, 0, 0, cv2.BORDER_REPLICATE)   
        ## where are the humans ?!?!
        
        humans, times = self._openpose.inference(self._frame_humans)
        ##self._bag_time.write('times_inference', times[0])

        if self._debug:
            rospy.loginfo("Inference times: %d - %d - %d ", times[0], imes[1], times[2])

        ## convert to ros msg
        humanArray_msg = self.humans_to_msg(humans, self._frame_humans, self._cloud)
        
        ## publish human array
        self._pub_human.publish(humanArray_msg)


if __name__ == '__main__':
    try:
        x = OpenposeClass()
        x.detect_humans()
    except rospy.ROSInterruptException: pass







